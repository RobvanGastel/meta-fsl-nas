{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import scipy.special\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/rob/Git/meta-fsl-nas/metanas\")\n",
    "\n",
    "import metanas.utils.genotypes as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"Model for a single DARTS cell\"\"\"\n",
    "    def __init__(self, n_ops=7, n_nodes=3):\n",
    "        self.n_ops = len(gt.PRIMITIVES_FEWSHOT)\n",
    "        self.n_nodes = 3\n",
    "\n",
    "        \n",
    "        self.encoded_states = []\n",
    "        self.states = []\n",
    "        self.topk = []\n",
    "        \n",
    "        self.alphas = []\n",
    "        self.norm_alphas = []\n",
    "\n",
    "        # Adjacency matrix\n",
    "        self.A = np.ones((self.n_nodes+2, self.n_nodes+2)) - np.eye(self.n_nodes+2)\n",
    "\n",
    "        # Remove the 2 input nodes from A\n",
    "        self.A[0, 1] = 0\n",
    "        self.A[1, 0] = 0\n",
    "\n",
    "        for i in range(n_nodes):\n",
    "            a = nn.Parameter(\n",
    "                1e-3 * torch.randn(i + 2, n_ops))\n",
    "            self.alphas.append(a)\n",
    "            self.norm_alphas.append(F.softmax(a, dim=-1))\n",
    "\n",
    "    def print_topk(self):\n",
    "        for i, edges in enumerate(self.norm_alphas):\n",
    "            # edges: Tensor(n_edges, n_ops)\n",
    "            edge_max, _ = torch.topk(edges[:, :], 1)\n",
    "            # selecting the top-k input nodes, k=2\n",
    "            _, topk_edge_indices = torch.topk(edge_max.view(-1), k=2)\n",
    "            \n",
    "            print(topk_edge_indices)\n",
    "    \n",
    "    def parse(self, alpha, k=2, primitives=gt.PRIMITIVES_FEWSHOT):\n",
    "        gene = []\n",
    "        for edges in alpha:\n",
    "            edge_max, primitive_indices = torch.topk(\n",
    "                edges[:, :], 1\n",
    "            )\n",
    "            \n",
    "#             print(edges[:,:], primitive_indices, edge_max, \"\\n\")\n",
    "\n",
    "            topk_edge_values, topk_edge_indices = torch.topk(\n",
    "                edge_max.view(-1), k)\n",
    "\n",
    "#             print(topk_edge_values, topk_edge_indices, \"\\n\")\n",
    "            \n",
    "            node_gene = []\n",
    "            for edge_idx in topk_edge_indices:\n",
    "                prim_idx = primitive_indices[edge_idx]\n",
    "                prim = primitives[prim_idx]\n",
    "                node_gene.append((prim, edge_idx.item()))\n",
    "\n",
    "            gene.append(node_gene)\n",
    "        return gene\n",
    "    \n",
    "    def calculate_states(self):\n",
    "        s_idx = 0\n",
    "        \n",
    "#         print(self.states)\n",
    "#         if current_states is not None:\n",
    "        prev_topk = copy.deepcopy(self.topk)\n",
    "        prev_edge = copy.deepcopy(self.encoded_states)\n",
    "        \n",
    "        self.topk = []\n",
    "        self.states = []\n",
    "        self.encoded_states = []\n",
    "        self.edge_to_index = {}\n",
    "        self.edge_to_alpha = {}\n",
    "\n",
    "        for i, edges in enumerate(self.norm_alphas):\n",
    "            # edges: Tensor(n_edges, n_ops)\n",
    "            edge_max, edge_idx = torch.topk(edges[:, :], 1)\n",
    "            \n",
    "            # selecting the top-k input nodes, k=2\n",
    "            _, topk_edge_indices = torch.topk(edge_max.view(-1), k=2)\n",
    "\n",
    "            edge_one_hot = torch.zeros_like(edges[:,:])\n",
    "            \n",
    "            \n",
    "            for hot_e, op in zip(edge_one_hot, edge_idx):\n",
    "                hot_e[op.item()] = 1\n",
    "\n",
    "            for j, edge in enumerate(edge_one_hot):\n",
    "                self.edge_to_index[(j, i+2)] = s_idx\n",
    "                self.edge_to_index[(i+2, j)] = s_idx+1\n",
    "\n",
    "                self.edge_to_alpha[(j, i+2)] = (i, j)\n",
    "                self.edge_to_alpha[(i+2, j)] = (i, j)\n",
    "\n",
    "                self.encoded_states.append(edge.numpy())\n",
    "                \n",
    "                # For undirected edge we add the edge twice\n",
    "                self.states.append([\n",
    "#                         f\"from:{j} to:{i+2}\",\n",
    "                        int(j in topk_edge_indices)])\n",
    "                \n",
    "                self.topk.append(\n",
    "#                         f\"from:{j} to:{i+2}\",\n",
    "                        [int(j in topk_edge_indices)])\n",
    "\n",
    "#                 self.states.append((\n",
    "#                         (f\"from:{i+2}\",\n",
    "#                         f\"to:{j}\"),\n",
    "#                         [int(j in topk_edge_indices)]))\n",
    "                s_idx += 2\n",
    "    \n",
    "        d = {'prev_topk': np.array(prev_topk),\n",
    "             'prev_edges': np.array(prev_edge)}\n",
    "    \n",
    "        self.encoded_states = np.array(self.encoded_states)\n",
    "#         change = (np.array(prev_topk) < np.array(self.topk))\n",
    "        return d, self.states\n",
    "    \n",
    "    def _inverse_softmax(self, x, C):\n",
    "        return torch.log(x) + C\n",
    "    \n",
    "    def increase_op(self, cur_node, next_node, op_idx, prob=0.7, n_ops=7):\n",
    "#         t_max = 5.0\n",
    "#         t_min = 0.1\n",
    "#         max_step = 6\n",
    "#         curr_step = 1\n",
    "#         # Temperature\n",
    "#         temp = t_max - curr_step * (t_max - t_min)/max_step-1\n",
    "\n",
    "        C = math.log(10.)\n",
    "\n",
    "        row_idx, edge_idx = self.edge_to_alpha[(cur_node, next_node)]\n",
    "        \n",
    "        # Set short-hands\n",
    "        curr_op = self.norm_alphas[row_idx][edge_idx][op_idx]\n",
    "        curr_edge = self.norm_alphas[row_idx][edge_idx]\n",
    "        \n",
    "                # Allow for increasing to 0.99\n",
    "        if curr_op + prob > 1.0:\n",
    "            surplus = curr_op + prob - 0.99\n",
    "            prob -= surplus\n",
    "\n",
    "        if curr_op + prob < 1.0:\n",
    "            # Increase chosen op\n",
    "            with torch.no_grad():\n",
    "                curr_op += prob\n",
    "\n",
    "            # Prevent 0.00 normalized alpha values, resulting in\n",
    "            # -inf\n",
    "            with torch.no_grad():\n",
    "                curr_edge += 0.01\n",
    "\n",
    "            # Set the meta-model, update the env state in\n",
    "            # self.update_states()\n",
    "            with torch.no_grad():\n",
    "                self.alphas[\n",
    "                    row_idx][edge_idx] = self._inverse_softmax(\n",
    "                    curr_edge, C)\n",
    "        \n",
    "        # /temp\n",
    "        self.norm_alphas = [\n",
    "            F.softmax(alpha, dim=-1).detach().cpu()\n",
    "            for alpha in self.alphas]\n",
    "    \n",
    "    def decrease_op(self, cur_node, next_node, op_idx, prob=0.7, n_ops=7):\n",
    "        C = math.log(10.)\n",
    "\n",
    "        row_idx, edge_idx = self.edge_to_alpha[(cur_node, next_node)]\n",
    "        \n",
    "        # Set short-hands\n",
    "        curr_op = self.norm_alphas[row_idx][edge_idx][op_idx]\n",
    "        curr_edge = self.norm_alphas[row_idx][edge_idx]\n",
    "        \n",
    "        # Allow for increasing to 0.99\n",
    "        if curr_op - prob < 0.0:\n",
    "            surplus = prob - curr_op + 0.01\n",
    "            print(surplus)\n",
    "            prob -= surplus\n",
    "            print(prob)\n",
    "\n",
    "        if curr_op - prob > 0.0:\n",
    "            # Increase chosen op\n",
    "            with torch.no_grad():\n",
    "                curr_op -= prob\n",
    "                \n",
    "            # Prevent 0.00 normalized alpha values, resulting in\n",
    "            # -inf\n",
    "            with torch.no_grad():\n",
    "                curr_edge += 0.01\n",
    "            \n",
    "            # Set the meta-model, update the env state in\n",
    "            # self.update_states()\n",
    "            with torch.no_grad():\n",
    "                self.alphas[\n",
    "                    row_idx][edge_idx] = self._inverse_softmax(\n",
    "                    curr_edge, C)\n",
    "            \n",
    "        self.norm_alphas = [\n",
    "            F.softmax(alpha, dim=-1).detach().cpu()\n",
    "            for alpha in self.alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "print(\"primitives:\", gt.PRIMITIVES_FEWSHOT, \"\\n\")\n",
    "model.print_topk(), model.parse(model.norm_alphas, k=2)\n",
    "\n",
    "_, b = model.calculate_states()\n",
    "print(\"init:\", b)\n",
    "\n",
    "model.increase_op(1, 2, 5)\n",
    "model.increase_op(1, 3, 3)\n",
    "\n",
    "d, _ = model.calculate_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import glob\n",
    "import shelve\n",
    "\n",
    "import igraph as ig\n",
    "from igraph import Graph\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph_path(path, last_steps=None, paths_left=5):\n",
    "    d = shelve.open(path)\n",
    "    walks = sum(d.values(), [])\n",
    "    d.close()\n",
    "    \n",
    "    if last_steps is not None:\n",
    "        walks = walks[:last_steps]\n",
    "        \n",
    "    # TODO: Starting path might be variable\n",
    "    path = [(0,2)]\n",
    "    weights = [1]\n",
    "\n",
    "    walks_temp = []\n",
    "    walks_curr = copy.deepcopy(walks)\n",
    "    max_k = len(walks)\n",
    "\n",
    "    for i in range(max_k):\n",
    "        edge_dict = {}\n",
    "        walks_temp = []\n",
    "\n",
    "        for j, walk in enumerate(walks_curr):\n",
    "            # Check if current walk is long enough\n",
    "            if i >= len(walk):\n",
    "                continue\n",
    "            else:\n",
    "                # Current step\n",
    "                w = walk[i]\n",
    "\n",
    "                if w in edge_dict:\n",
    "                    edge_dict[w] += 1\n",
    "                else:\n",
    "                    edge_dict[w] = 1\n",
    "\n",
    "                walks_temp.append(walk)\n",
    "\n",
    "        # Stop if the path ended or,\n",
    "        if len(edge_dict) == 0:\n",
    "            break\n",
    "        # Or if only 5 walks are left \n",
    "        if sum([v for v in edge_dict.values()]) < paths_left:\n",
    "            break\n",
    "\n",
    "        # Step with highest count\n",
    "        max_edge = max(edge_dict, key=edge_dict.get)\n",
    "        path.append(max_edge)\n",
    "        weights.append(edge_dict[max_edge]/(sum(edge_dict.values())))\n",
    "\n",
    "        for walk in walks_temp:\n",
    "            if walk[i] != max_edge:\n",
    "                walks_temp.remove(walk)\n",
    "        walks_curr = copy.deepcopy(walks_temp)\n",
    "        \n",
    "        return path, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gif(path, weights, save_paths, format_path):\n",
    "    for f in save_paths:\n",
    "        os.remove(f)\n",
    "\n",
    "    edges = [(0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
    "    edge_color = [\"gray\"]*len(edges)\n",
    "\n",
    "    for i, (edge, weight) in enumerate(zip(path, weights)):\n",
    "        edges = [(0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
    "        g = Graph(edges)\n",
    "\n",
    "        if edge in edges:\n",
    "            index = edges.index(edge)\n",
    "        else:\n",
    "            index = edges.index((edge[1], edge[0]))\n",
    "\n",
    "        edge_color[index] = 'red'\n",
    "\n",
    "        lb = [\"\"]*len(edges)\n",
    "        lb[index] = f\"step {i}: {edge[0]} -> {edge[1]}, weight: {weight:.2f}\"\n",
    "\n",
    "        # 5 Nodes\n",
    "        g.vs[\"label\"] = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "        g.vs[\"input\"] = [True, True, False, False, False]\n",
    "        g.es[\"color\"] = edge_color\n",
    "        g.es[\"label\"] = lb\n",
    "\n",
    "        ig.plot(\n",
    "            g, \n",
    "            vertex_size=40, \n",
    "            edge_width=[3],\n",
    "            vertex_color=['yellow', 'yellow', 'blue', 'blue', 'blue'],\n",
    "            target=format_path.format(i),\n",
    "            bbox=(800, 800),\n",
    "            margin=200\n",
    "        )\n",
    "        edge_color[index] = 'purple'\n",
    "\n",
    "    frames = []\n",
    "    for img in sorted(glob.glob(save_paths), key=os.path.getmtime):\n",
    "        frames.append(Image.open(img))\n",
    "\n",
    "    frames[0].save('graph_walk.gif', format='GIF', append_images=frames[1:],\n",
    "        save_all=True, duration=1800, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/rob/Git/meta-fsl-nas/metanas/results/triplemnist/ppo_metad2a_environment_1/seed_2/graph_walk.shlv\"\n",
    "save_paths = glob.glob(\"/home/rob/Git/meta-fsl-nas/notebooks/path/*.png\")\n",
    "format_path = \"/home/rob/Git/meta-fsl-nas/notebooks/path/{0}.png\"\n",
    "\n",
    "path, weights = generate_graph_path(path)\n",
    "generate_gif(path, weights, save_paths, format_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_mean_std_dataset(path):\n",
    "    mean_sum = np.array([0., 0., 0.])\n",
    "    std_sum = np.array([0., 0., 0.])\n",
    "    \n",
    "    n_images = 0\n",
    "    for file in list(glob.glob(path)):\n",
    "        img = cv.imread(file)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = img/255\n",
    "        mean, std = cv.meanStdDev(img)\n",
    "        \n",
    "        mean_sum += np.squeeze(mean)\n",
    "        std_sum += np.squeeze(std)\n",
    "        n_images += 1\n",
    "    return (mean_sum / n_images, std_sum / n_images)\n",
    "\n",
    "path = '/home/rob/Desktop/meta5/*/*/*.png'\n",
    "\n",
    "mean, std = calc_avg_mean_std_dataset(path)\n",
    "print(mean, std)\n",
    "\n",
    "print(\"{:0.4f}, {:0.4f}\".format(mean[0], std[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Load model back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_path = '/home/rob/Git/meta-fsl-nas/metanas/results/omniprint/ppo_debug/seed_2/_s2/vars1.pkl'\n",
    "model_path = '/home/rob/Git/meta-fsl-nas/metanas/results/omniprint/ppo_debug/seed_2/_s2/pyt_save/model1.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(torch.load(model_path)['ac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pickle.load(open(vars_path, 'rb'))\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from torchmeta.utils.data import Dataset, ClassDataset, CombinationMetaDataset\n",
    "from torchmeta.datasets.utils import download_file_from_google_drive\n",
    "from torchmeta.datasets.helpers import helper_with_default\n",
    "\n",
    "\n",
    "def omniprint(folder, shots, ways, shuffle=True, test_shots=None,\n",
    "              seed=None, **kwargs):\n",
    "    return helper_with_default(OmniPrint, folder, shots, ways,\n",
    "                               shuffle=shuffle, test_shots=test_shots,\n",
    "                               seed=seed, **kwargs)\n",
    "\n",
    "\n",
    "class OmniPrint(CombinationMetaDataset):\n",
    "    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n",
    "                 meta_val=False, meta_test=False, meta_split=None,\n",
    "                 transform=None, target_transform=None, dataset_transform=None,\n",
    "                 class_augmentations=None, download=False,\n",
    "                 print_split='meta1',  # Addition for the OmniPrint dataset\n",
    "                 ):\n",
    "        dataset = OmniPrintClassDataset(\n",
    "            root, meta_train=meta_train,\n",
    "            meta_val=meta_val, meta_test=meta_test,\n",
    "            print_split=print_split, transform=transform,\n",
    "            meta_split=meta_split,\n",
    "            class_augmentations=class_augmentations,\n",
    "            download=download)\n",
    "        super(OmniPrint, self).__init__(\n",
    "            dataset, num_classes_per_task,\n",
    "            target_transform=target_transform,\n",
    "            dataset_transform=dataset_transform)\n",
    "\n",
    "\n",
    "class OmniPrintClassDataset(ClassDataset):\n",
    "    gdrive_id = '1JBXYMTsdlm8RaEBPqrJbDRzs3hJ4q_gH'\n",
    "    folder = 'omniprint'\n",
    "\n",
    "    zip_filename = '{0}.zip'\n",
    "    filename = '{0}_{1}_data.hdf5'\n",
    "    filename_labels = '{0}_{1}_labels.json'\n",
    "\n",
    "    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n",
    "                 meta_split=None, print_split=None, transform=None,\n",
    "                 class_augmentations=None, download=False):\n",
    "        super(OmniPrintClassDataset, self).__init__(\n",
    "            meta_train=meta_train,\n",
    "            meta_val=meta_val,\n",
    "            meta_test=meta_test,\n",
    "            meta_split=meta_split,\n",
    "            class_augmentations=class_augmentations)\n",
    "\n",
    "        self.root = os.path.join(os.path.expanduser(\n",
    "            root), self.folder)\n",
    "        self.print_split = print_split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.split_filename = os.path.join(\n",
    "            self.root,\n",
    "            self.filename.format(print_split, self.meta_split))\n",
    "        self.split_filename_labels = os.path.join(\n",
    "            self.root,\n",
    "            self.filename_labels.format(print_split, self.meta_split))\n",
    "\n",
    "        self._data = None\n",
    "        self._labels = None\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('OmniPrint integrity check failed')\n",
    "        self._num_classes = len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        character_name = '/'.join(self.labels[index % self.num_classes])\n",
    "        data = self.data[character_name]\n",
    "        transform = self.get_transform(index, self.transform)\n",
    "        target_transform = self.get_target_transform(index)\n",
    "\n",
    "        return OmniPrintDataset(\n",
    "            index, data, character_name,\n",
    "            transform=transform, target_transform=target_transform)\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self._num_classes\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        if self._data is None:\n",
    "            self._data = h5py.File(self.split_filename, 'r')\n",
    "        return self._data\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        if self._labels is None:\n",
    "            with open(self.split_filename_labels, 'r') as f:\n",
    "                self._labels = json.load(f)\n",
    "        return self._labels\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        return (os.path.isfile(self.split_filename)\n",
    "                and os.path.isfile(self.split_filename_labels))\n",
    "\n",
    "    def close(self):\n",
    "        if self._data is not None:\n",
    "            self._data.close()\n",
    "            self._data = None\n",
    "\n",
    "    def download(self):\n",
    "        import zipfile\n",
    "        import shutil\n",
    "        import glob\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        if self._check_integrity():\n",
    "            return\n",
    "\n",
    "        zip_foldername = os.path.join(\n",
    "            self.root, self.zip_filename.format(self.folder))\n",
    "        # Download the datasets\n",
    "        if not os.path.isfile(zip_foldername):\n",
    "            download_file_from_google_drive(\n",
    "                self.gdrive_id, self.root,\n",
    "                self.zip_filename.format(self.folder))\n",
    "\n",
    "        # Unzip the dataset\n",
    "        if not os.path.isdir(zip_foldername):\n",
    "            with zipfile.ZipFile(zip_foldername) as f:\n",
    "                for member in tqdm(f.infolist(), desc='Extracting '):\n",
    "                    try:\n",
    "                        f.extract(member, self.root)\n",
    "                    except zipfile.BadZipFile:\n",
    "                        print('Error: Zipfile is corrupted')\n",
    "\n",
    "        for print_split in ['meta1', 'meta2', 'meta3', 'meta4', 'meta5']:\n",
    "            for split in tqdm(['train', 'val', 'test'], desc=print_split):\n",
    "                filename_labels = os.path.join(\n",
    "                    self.root, self.filename_labels.format(print_split, split))\n",
    "\n",
    "                with open(filename_labels, 'r') as f:\n",
    "                    labels = json.load(f)\n",
    "\n",
    "                filename = os.path.join(\n",
    "                    self.root, self.filename.format(print_split, split))\n",
    "\n",
    "                with h5py.File(filename, 'w') as f:\n",
    "                    group = f.create_group(print_split)\n",
    "                    for _, alphabet, character in labels:\n",
    "                        filenames = glob.glob(\n",
    "                            os.path.join(\n",
    "                                self.root, print_split,\n",
    "                                alphabet, character, '*.png'))\n",
    "                        dataset = group.create_dataset('{0}/{1}'.format(\n",
    "                            alphabet, character),\n",
    "                            (len(filenames), 32, 32),\n",
    "                            dtype='uint8')\n",
    "\n",
    "                        for i, char_filename in enumerate(filenames):\n",
    "                            image = Image.open(\n",
    "                                char_filename, mode='r').convert('L')\n",
    "                            dataset[i] = image\n",
    "\n",
    "            shutil.rmtree(os.path.join(self.root, print_split))\n",
    "\n",
    "\n",
    "class OmniPrintDataset(Dataset):\n",
    "    def __init__(self, index, data, character_name,\n",
    "                 transform=None, target_transform=None):\n",
    "        super(OmniPrintDataset, self).__init__(\n",
    "            index, transform=transform,\n",
    "            target_transform=target_transform)\n",
    "        self.data = data\n",
    "        self.character_name = character_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.fromarray(self.data[index])\n",
    "        target = self.character_name\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return (image, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "\n",
    "\n",
    "dataset = omniprint(\n",
    "        \"/home/rob/Desktop\",\n",
    "        1,\n",
    "        5,\n",
    "        print_split='meta1',\n",
    "        meta_split='val',\n",
    "        test_shots=1,\n",
    "        download=True,\n",
    "        seed=1,\n",
    ")\n",
    "\n",
    "dataloader = BatchMetaDataLoader(\n",
    "    dataset, batch_size=1, num_workers=1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(next(iter(dataloader))['train'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
