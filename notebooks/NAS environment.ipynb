{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "western-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import scipy.special\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/rob/Git/meta-fsl-nas/metanas\")\n",
    "\n",
    "import metanas.utils.genotypes as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "comparable-separate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig tensor([ 1.1632, -0.5108, -1.6094, -0.9163,  0.8755,  1.3083, -2.3026],\n",
      "       grad_fn=<SelectBackward>)\n",
      "norm tensor([0.3019, 0.0566, 0.0189, 0.0377, 0.2264, 0.3491, 0.0094],\n",
      "       grad_fn=<SelectBackward>) tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    \"\"\"Model for a single DARTS cell\"\"\"\n",
    "    def __init__(self, n_ops=7, n_nodes=3):\n",
    "        self.n_ops = len(gt.PRIMITIVES_FEWSHOT)\n",
    "        self.n_nodes = 3\n",
    "\n",
    "        \n",
    "        self.encoded_states = []\n",
    "        self.states = []\n",
    "        self.topk = []\n",
    "        \n",
    "        self.alphas = []\n",
    "        self.norm_alphas = []\n",
    "\n",
    "        # Adjacency matrix\n",
    "        self.A = np.ones((self.n_nodes+2, self.n_nodes+2)) - np.eye(self.n_nodes+2)\n",
    "\n",
    "        # Remove the 2 input nodes from A\n",
    "        self.A[0, 1] = 0\n",
    "        self.A[1, 0] = 0\n",
    "\n",
    "        for i in range(n_nodes):\n",
    "            a = nn.Parameter(\n",
    "                1e-3 * torch.randn(i + 2, n_ops))\n",
    "            self.alphas.append(a)\n",
    "            self.norm_alphas.append(F.softmax(a, dim=-1))\n",
    "\n",
    "    def print_topk(self):\n",
    "        for i, edges in enumerate(self.norm_alphas):\n",
    "            # edges: Tensor(n_edges, n_ops)\n",
    "            edge_max, _ = torch.topk(edges[:, :], 1)\n",
    "            # selecting the top-k input nodes, k=2\n",
    "            _, topk_edge_indices = torch.topk(edge_max.view(-1), k=2)\n",
    "            \n",
    "            print(topk_edge_indices)\n",
    "    \n",
    "    def parse(self, alpha, k=2, primitives=gt.PRIMITIVES_FEWSHOT):\n",
    "        gene = []\n",
    "        for edges in alpha:\n",
    "            edge_max, primitive_indices = torch.topk(\n",
    "                edges[:, :], 1\n",
    "            )\n",
    "            \n",
    "#             print(edges[:,:], primitive_indices, edge_max, \"\\n\")\n",
    "\n",
    "            topk_edge_values, topk_edge_indices = torch.topk(\n",
    "                edge_max.view(-1), k)\n",
    "\n",
    "#             print(topk_edge_values, topk_edge_indices, \"\\n\")\n",
    "            \n",
    "            node_gene = []\n",
    "            for edge_idx in topk_edge_indices:\n",
    "                prim_idx = primitive_indices[edge_idx]\n",
    "                prim = primitives[prim_idx]\n",
    "                node_gene.append((prim, edge_idx.item()))\n",
    "\n",
    "            gene.append(node_gene)\n",
    "        return gene\n",
    "    \n",
    "    def calculate_states(self):\n",
    "        s_idx = 0\n",
    "        \n",
    "#         print(self.states)\n",
    "#         if current_states is not None:\n",
    "        prev_topk = copy.deepcopy(self.topk)\n",
    "        prev_edge = copy.deepcopy(self.encoded_states)\n",
    "        \n",
    "        self.topk = []\n",
    "        self.states = []\n",
    "        self.encoded_states = []\n",
    "        self.edge_to_index = {}\n",
    "        self.edge_to_alpha = {}\n",
    "\n",
    "        for i, edges in enumerate(self.norm_alphas):\n",
    "            # edges: Tensor(n_edges, n_ops)\n",
    "            edge_max, edge_idx = torch.topk(edges[:, :], 1)\n",
    "            \n",
    "            # selecting the top-k input nodes, k=2\n",
    "            _, topk_edge_indices = torch.topk(edge_max.view(-1), k=2)\n",
    "\n",
    "            edge_one_hot = torch.zeros_like(edges[:,:])\n",
    "            \n",
    "            \n",
    "            for hot_e, op in zip(edge_one_hot, edge_idx):\n",
    "                hot_e[op.item()] = 1\n",
    "\n",
    "            for j, edge in enumerate(edge_one_hot):\n",
    "                self.edge_to_index[(j, i+2)] = s_idx\n",
    "                self.edge_to_index[(i+2, j)] = s_idx+1\n",
    "\n",
    "                self.edge_to_alpha[(j, i+2)] = (i, j)\n",
    "                self.edge_to_alpha[(i+2, j)] = (i, j)\n",
    "\n",
    "                self.encoded_states.append(edge.numpy())\n",
    "                \n",
    "                # For undirected edge we add the edge twice\n",
    "                self.states.append([\n",
    "#                         f\"from:{j} to:{i+2}\",\n",
    "                        int(j in topk_edge_indices)])\n",
    "                \n",
    "                self.topk.append(\n",
    "#                         f\"from:{j} to:{i+2}\",\n",
    "                        [int(j in topk_edge_indices)])\n",
    "\n",
    "#                 self.states.append((\n",
    "#                         (f\"from:{i+2}\",\n",
    "#                         f\"to:{j}\"),\n",
    "#                         [int(j in topk_edge_indices)]))\n",
    "                s_idx += 2\n",
    "    \n",
    "        d = {'prev_topk': np.array(prev_topk),\n",
    "             'prev_edges': np.array(prev_edge)}\n",
    "    \n",
    "        self.encoded_states = np.array(self.encoded_states)\n",
    "#         change = (np.array(prev_topk) < np.array(self.topk))\n",
    "        return d, self.states\n",
    "    \n",
    "    def _inverse_softmax(self, x, C):\n",
    "        return torch.log(x) + C\n",
    "    \n",
    "    def increase_op(self, cur_node, next_node, op_idx, prob=0.7, n_ops=7):\n",
    "#         t_max = 5.0\n",
    "#         t_min = 0.1\n",
    "#         max_step = 6\n",
    "#         curr_step = 1\n",
    "#         # Temperature\n",
    "#         temp = t_max - curr_step * (t_max - t_min)/max_step-1\n",
    "\n",
    "        C = math.log(10.)\n",
    "\n",
    "        row_idx, edge_idx = self.edge_to_alpha[(cur_node, next_node)]\n",
    "        \n",
    "        # Set short-hands\n",
    "        curr_op = self.norm_alphas[row_idx][edge_idx][op_idx]\n",
    "        curr_edge = self.norm_alphas[row_idx][edge_idx]\n",
    "        \n",
    "                # Allow for increasing to 0.99\n",
    "        if curr_op + prob > 1.0:\n",
    "            surplus = curr_op + prob - 0.99\n",
    "            prob -= surplus\n",
    "\n",
    "        if curr_op + prob < 1.0:\n",
    "            # Increase chosen op\n",
    "            with torch.no_grad():\n",
    "                curr_op += prob\n",
    "\n",
    "            # Prevent 0.00 normalized alpha values, resulting in\n",
    "            # -inf\n",
    "            with torch.no_grad():\n",
    "                curr_edge += 0.01\n",
    "\n",
    "            # Set the meta-model, update the env state in\n",
    "            # self.update_states()\n",
    "            with torch.no_grad():\n",
    "                self.alphas[\n",
    "                    row_idx][edge_idx] = self._inverse_softmax(\n",
    "                    curr_edge, C)\n",
    "        \n",
    "        # /temp\n",
    "        self.norm_alphas = [\n",
    "            F.softmax(alpha, dim=-1).detach().cpu()\n",
    "            for alpha in self.alphas]\n",
    "    \n",
    "    def decrease_op(self, cur_node, next_node, op_idx, prob=0.7, n_ops=7):\n",
    "        C = math.log(10.)\n",
    "\n",
    "        row_idx, edge_idx = self.edge_to_alpha[(cur_node, next_node)]\n",
    "        \n",
    "        # Set short-hands\n",
    "        curr_op = self.norm_alphas[row_idx][edge_idx][op_idx]\n",
    "        curr_edge = self.norm_alphas[row_idx][edge_idx]\n",
    "        \n",
    "        # Allow for increasing to 0.99\n",
    "        if curr_op - prob < 0.0:\n",
    "            surplus = prob - curr_op + 0.01\n",
    "            print(surplus)\n",
    "            prob -= surplus\n",
    "            print(prob)\n",
    "\n",
    "        if curr_op - prob > 0.0:\n",
    "            # Increase chosen op\n",
    "            with torch.no_grad():\n",
    "                curr_op -= prob\n",
    "                \n",
    "            # Prevent 0.00 normalized alpha values, resulting in\n",
    "            # -inf\n",
    "            with torch.no_grad():\n",
    "                curr_edge += 0.01\n",
    "            \n",
    "            # Set the meta-model, update the env state in\n",
    "            # self.update_states()\n",
    "            with torch.no_grad():\n",
    "                self.alphas[\n",
    "                    row_idx][edge_idx] = self._inverse_softmax(\n",
    "                    curr_edge, C)\n",
    "            \n",
    "        self.norm_alphas = [\n",
    "            F.softmax(alpha, dim=-1).detach().cpu()\n",
    "            for alpha in self.alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "print(\"primitives:\", gt.PRIMITIVES_FEWSHOT, \"\\n\")\n",
    "model.print_topk(), model.parse(model.norm_alphas, k=2)\n",
    "\n",
    "_, b = model.calculate_states()\n",
    "print(\"init:\", b)\n",
    "\n",
    "model.increase_op(1, 2, 5)\n",
    "model.increase_op(1, 3, 3)\n",
    "\n",
    "d, _ = model.calculate_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-overview",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-processing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import glob\n",
    "import shelve\n",
    "\n",
    "import igraph as ig\n",
    "from igraph import Graph\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph_path(path, last_steps=None, paths_left=5):\n",
    "    d = shelve.open(path)\n",
    "    walks = sum(d.values(), [])\n",
    "    d.close()\n",
    "    \n",
    "    if last_steps is not None:\n",
    "        walks = walks[:last_steps]\n",
    "        \n",
    "    # TODO: Starting path might be variable\n",
    "    path = [(0,2)]\n",
    "    weights = [1]\n",
    "\n",
    "    walks_temp = []\n",
    "    walks_curr = copy.deepcopy(walks)\n",
    "    max_k = len(walks)\n",
    "\n",
    "    for i in range(max_k):\n",
    "        edge_dict = {}\n",
    "        walks_temp = []\n",
    "\n",
    "        for j, walk in enumerate(walks_curr):\n",
    "            # Check if current walk is long enough\n",
    "            if i >= len(walk):\n",
    "                continue\n",
    "            else:\n",
    "                # Current step\n",
    "                w = walk[i]\n",
    "\n",
    "                if w in edge_dict:\n",
    "                    edge_dict[w] += 1\n",
    "                else:\n",
    "                    edge_dict[w] = 1\n",
    "\n",
    "                walks_temp.append(walk)\n",
    "\n",
    "        # Stop if the path ended or,\n",
    "        if len(edge_dict) == 0:\n",
    "            break\n",
    "        # Or if only 5 walks are left \n",
    "        if sum([v for v in edge_dict.values()]) < paths_left:\n",
    "            break\n",
    "\n",
    "        # Step with highest count\n",
    "        max_edge = max(edge_dict, key=edge_dict.get)\n",
    "        path.append(max_edge)\n",
    "        weights.append(edge_dict[max_edge]/(sum(edge_dict.values())))\n",
    "\n",
    "        for walk in walks_temp:\n",
    "            if walk[i] != max_edge:\n",
    "                walks_temp.remove(walk)\n",
    "        walks_curr = copy.deepcopy(walks_temp)\n",
    "        \n",
    "        return path, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gif(path, weights, save_paths, format_path):\n",
    "    for f in save_paths:\n",
    "        os.remove(f)\n",
    "\n",
    "    edges = [(0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
    "    edge_color = [\"gray\"]*len(edges)\n",
    "\n",
    "    for i, (edge, weight) in enumerate(zip(path, weights)):\n",
    "        edges = [(0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
    "        g = Graph(edges)\n",
    "\n",
    "        if edge in edges:\n",
    "            index = edges.index(edge)\n",
    "        else:\n",
    "            index = edges.index((edge[1], edge[0]))\n",
    "\n",
    "        edge_color[index] = 'red'\n",
    "\n",
    "        lb = [\"\"]*len(edges)\n",
    "        lb[index] = f\"step {i}: {edge[0]} -> {edge[1]}, weight: {weight:.2f}\"\n",
    "\n",
    "        # 5 Nodes\n",
    "        g.vs[\"label\"] = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "        g.vs[\"input\"] = [True, True, False, False, False]\n",
    "        g.es[\"color\"] = edge_color\n",
    "        g.es[\"label\"] = lb\n",
    "\n",
    "        ig.plot(\n",
    "            g, \n",
    "            vertex_size=40, \n",
    "            edge_width=[3],\n",
    "            vertex_color=['yellow', 'yellow', 'blue', 'blue', 'blue'],\n",
    "            target=format_path.format(i),\n",
    "            bbox=(800, 800),\n",
    "            margin=200\n",
    "        )\n",
    "        edge_color[index] = 'purple'\n",
    "\n",
    "    frames = []\n",
    "    for img in sorted(glob.glob(save_paths), key=os.path.getmtime):\n",
    "        frames.append(Image.open(img))\n",
    "\n",
    "    frames[0].save('graph_walk.gif', format='GIF', append_images=frames[1:],\n",
    "        save_all=True, duration=1800, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/rob/Git/meta-fsl-nas/metanas/results/triplemnist/ppo_metad2a_environment_1/seed_2/graph_walk.shlv\"\n",
    "save_paths = glob.glob(\"/home/rob/Git/meta-fsl-nas/notebooks/path/*.png\")\n",
    "format_path = \"/home/rob/Git/meta-fsl-nas/notebooks/path/{0}.png\"\n",
    "\n",
    "path, weights = generate_graph_path(path)\n",
    "generate_gif(path, weights, save_paths, format_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-recall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_mean_std_dataset(path, img_names, img_root):\n",
    "    mean_sum = np.array([0., 0., 0.])\n",
    "    std_sum = np.array([0., 0., 0.])\n",
    "    \n",
    "    n_images = 0\n",
    "    for file in list(glob.glob()):\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img/255\n",
    "        mean, std = cv2.meanStdDev(img)\n",
    "        \n",
    "        mean_sum += np.squeeze(mean)\n",
    "        std_sum += np.squeeze(std)\n",
    "        n_images += 1\n",
    "    return (mean_sum / n_images, std_sum / n_images)\n",
    "\n",
    "path = '/home/rob/Git/meta-fsl-nas/data/triplemnist/triple_mnist_seed_123_image_size_84_84/*/*/*.png'\n",
    "\n",
    "mean, std = calc_avg_mean_std_dataset(path, img_names, img_root)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-nebraska",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-equipment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-topic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-hungarian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
